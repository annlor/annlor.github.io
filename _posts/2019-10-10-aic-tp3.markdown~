---
layout: post
title:  "tp3 AIC - recherche d'information"
date:   2018-10-01 10:45:00 +0200
categories: ens aic
---


Le but de ces exercices est d'étudier les caractéristiques du vocabulaire dans les documents et leur utilisation pour de la recherche de documents. Chaque exercice permet d'en étudier un aspect.

Les fichiers et ressources pour le TP sont dans `/public/master_aic_rei/tp3`

Vous avez à votre disposition le script ri_basic.py qui contient quelques fonctions utiles, et que vous devrez compléter.

Pour plus d'informations:
- [la documentation de nltk concernant les prétraitements et l'analyse morpho-syntaxique](http://www.nltk.org/book/ch03.html)
- [la documentation de scikitlearn concernant les traitements textuels](http://scikit-learn.org/stable/modules/feature_extraction.html)

Pour installer scikit-learn si vous ne l'avez pas encore:
- créez un environnement python `python3 -m venv envtp`
- lancez le: `source envtp/bin/activate`
- installez le package: `pip install -U scikit-learn` (si nécessaire mettez à jour pip: `pip install --upgrade pip`)


# Exercice 1: étude des lexiques

## Comptages lexicaux

Générez la liste des 1000 mots les plus fréquents du corpus.
- Quels sont les mots les plus fréquents ? Pourquoi ?
- Constituent-ils de bons descripteurs des textes ?
- Comment pourrait-on choisir de meilleurs descripteurs ?

Générez la liste des 1000 lemmes ou racines les plus fréquents.
- Quelles différences constatez-vous ? Donnez des exemples.
- Quel problème a-t-il été traité avec les lemmes ?

Générez les 15 catégories les plus fréquentes.
- Quelle est la catégorie la plus fréquente ? Est-ce une bonne chose ? Pourquoi ?
- Quelle(s) catégorie(s) garderiez-vous pour obtenir de bons descripteurs ? Pourquoi ?

## Représentation graphique

- Créez une représentation graphique avec plot prenant en abscisse une fréquence et en ordonnée le nombre de tokens et de lemmes ayant cette fréquence (échelle log).

# Exercice 2: calcul de similarité et pertinence de la recherche
Le but est de sélectionner des textes proches d'une requête. Afin de calculer leur similarité, ils seront représentés
chacun par l'ensemble des termes que vous aurez retenus comme descripteurs auxquels on associera un poids, au moins
côté documents.


## Pondération des termes

- Comparer la fréquence des termes dans un texte et leur tfidf. Que constatez-vous en terme de poids par rapport à la fréquence ? Donnez des exemples. À quoi est-ce dû ?

## Calcul de similarités
Les requêtes sont en réalité des questions, qui sont dans le répertoire data/questions (la question rd_12_q_2.txt correspond par exemple à la deuxième question sur le document 2).

Calculez la similarité entre chaque question et les passages de textes issus du document associé.

Le script eval/eval.py vous permet de calculer une métrique d'évaluation appelée Mean Reciprocal Rank (MRR) au rang n:
MRR(n) = 1/nbquestions * somme (1/rangcorrect) avec rangcorrect <= n

- Calculez le MRR pour le script courant.
- Les textes les plus pertinents le sont-ils réellement selon la référence ? Si ce n'est pas le cas, quels sont les
descripteurs responsables ?

## Amélioration de la similarité

- Au vu des causes d'erreurs, améliorez la recherche en faisant varier les mesures de similarité, et en trouvant des
critères et des méthodes pour enlever automatiquement les mauvais descripteurs si il y en a dans les requêtes.

## Expansion de requête
Pour rapprocher les vecteurs, on peut étendre automatiquement les requêtes avec des mots proches (même famille morphologique ou synonymes), ou on peut appliquer du stemming, ou encore étendre la requête avec les mots de plus fort poids des premiers documents renvoyés (relevance feedback).

Le répertoire `data` contient deux fichiers: `der-families-en.utf8` pour les familles morphologiques et `sem-families-wn.utf8` pour les synonymes.

- Ecrivez un programme d'expansion de requête permettant de tester différents types d'expansion. Évaluez et commentez les
résultats.

